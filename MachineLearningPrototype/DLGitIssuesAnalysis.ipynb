{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import tempfile\n",
    "import pprint\n",
    "import math\n",
    "import random\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "\n",
    "'''Classifiers'''\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from joblib import dump, load\n",
    "import pickle\n",
    "\n",
    "from utils.preprocess_data import remove_time_stamp\n",
    "\n",
    "#from utils.queryDB import queryDBForTestOutput\n",
    "# from preprocessData import generateFeatureWordsList, generateLabelsIndex, \\\n",
    "#                             preprocessDBData, shuffleDataLabelPairs, \\\n",
    "#                             padding_processed_data, preprocessTFIDFData\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "train_data_path = 'data/GitHubData/IssueContent'\n",
    "train_data_extra_path = 'data/GitHubData/IssueContentQuote'\n",
    "train_data = []\n",
    "train_label = []\n",
    "\n",
    "train_files = os.listdir(train_data_path)\n",
    "train_files_extra = os.listdir(train_data_extra_path)\n",
    "\n",
    "for train_file in train_files:\n",
    "    if (train_file.endswith('txt')):\n",
    "        cur_train_label = train_file.strip(\".txt\")\n",
    "        train_label.append(cur_train_label)\n",
    "\n",
    "        cur_train_data = \"\"\n",
    "        with open(os.path.join(train_data_path, train_file)) as f1:\n",
    "            cur_train_data += f1.read()\n",
    "        # Attach related extra quotes file data if exists\n",
    "        possible_quotes_filename = cur_train_label + \"_quotes.txt\"\n",
    "        possible_quotes_file_path = os.path.join(train_data_extra_path, possible_quotes_filename)\n",
    "        if os.path.isfile(possible_quotes_file_path):\n",
    "            with open(possible_quotes_file_path) as f2:\n",
    "                cur_train_data += f2.read()\n",
    "        train_data.append(cur_train_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_git = pd.DataFrame([train_data, train_label]).T\n",
    "df_git.columns= ['git_issue_content', 'labels']\n",
    "df_git.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pre-process git data\n",
    "df_git['git_issue_content'] = [remove_time_stamp(content) for content in df_git['git_issue_content']]\n",
    "df_git.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_data_path = 'data/JenkinsData'\n",
    "test_data = []\n",
    "test_label = []\n",
    "\n",
    "test_files = os.listdir(test_data_path)\n",
    "for test_file in test_files:\n",
    "    if (test_file.endswith('txt')):\n",
    "        # test_label needs to remove .txt and trailing links (_http...) in file name, e.g. from openj9_1.txt and openj9_1_httpxxx.txt\n",
    "        cur_test_label = test_file.strip(\".txt\").split(\"_http\")[0]\n",
    "        test_label.append(cur_test_label)\n",
    "        with open(os.path.join(test_data_path, test_file)) as f:\n",
    "            test_data.append(f.read())\n",
    "\n",
    "df_jenkins = pd.DataFrame([test_data, test_label]).T\n",
    "df_jenkins.columns= ['jenkins_content', 'labels']\n",
    "df_jenkins.head()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# pre-process jenkins data\n",
    "df_jenkins['jenkins_content'] = [remove_time_stamp(content) for content in df_jenkins['jenkins_content']]\n",
    "df_jenkins.head()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# add train test matching in df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# df_git['clean_text'] = df_git['git_issue_content'].apply(process_text)\n",
    "# df_git.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clean_df_git = df_git.copy()\n",
    "\n",
    "def create_label_dict(labels, label_dict_name2num, label_dict_num2name):\n",
    "    index = 0\n",
    "    for label in labels:\n",
    "        if label not in label_dict_name2num:\n",
    "            label_dict_num2name[index] = label.rstrip('.txt')\n",
    "            label_dict_name2num[label] = index\n",
    "            index += 1\n",
    "\n",
    "labels_git_name = clean_df_git.pop(\"labels\") \n",
    "label_dict_name2num = dict()\n",
    "label_dict_num2name = dict()\n",
    "create_label_dict(labels_git_name, label_dict_name2num, label_dict_num2name)\n",
    "labels_git_num = [label_dict_name2num[x] for x in labels_git_name]"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# save num2name for TRSS use\n",
    "try: \n",
    "    os.makedirs('data/TempData', exist_ok=True)\n",
    "    num2name_file = open('data/TempData/num2name_file', 'wb')\n",
    "    pickle.dump(label_dict_num2name, num2name_file)\n",
    "    num2name_file.close() \n",
    "  \n",
    "except:\n",
    "    print(\"Failed to save num2name_file\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clean_df_git.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# tfidf can add more parameter settings\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer_train_vectors = tfidf_vectorizer.fit_transform(clean_df_git.pop('git_issue_content'))\n",
    "\n",
    "\n",
    "# save vectorizer for TRSS use\n",
    "try: \n",
    "    vectorizer_file = open('data/TempData/vectorizer_file.pk', 'wb')\n",
    "    pickle.dump(tfidf_vectorizer, vectorizer_file)\n",
    "    vectorizer_file.close()\n",
    "except: \n",
    "    print(\"Failed to save vectorizer_file\")\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame.sparse.from_spmatrix(tfidf_vectorizer_train_vectors, columns=tfidf_vectorizer.get_feature_names())\n",
    "print(\"train data after tfidf: \\n\", train_df.head())\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# add val when more data available\n",
    "val_df = train_df\n",
    "\n",
    "# test df is from jenkins\n",
    "clean_df_jenkins = df_jenkins.copy()\n",
    "labels_jenkins_name = clean_df_jenkins.pop(\"labels\")\n",
    "labels_jenkins_num = [label_dict_name2num[x] for x in labels_jenkins_name]\n",
    "print(\"test labels list: \", labels_jenkins_num)\n",
    "test_df = pd.DataFrame.sparse.from_spmatrix(tfidf_vectorizer.transform(clean_df_jenkins.pop('jenkins_content')), columns=tfidf_vectorizer.get_feature_names())\n",
    "print(\"test data after tfidf: \\n\", test_df.head())"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_labels = np.array(labels_git_num)\n",
    "# add val when more data available# add val when more data available\n",
    "val_labels = np.array(labels_git_num)\n",
    "test_labels = np.array(labels_jenkins_num)\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Normalize the input features using the sklearn StandardScaler. This will set the mean to 0 and standard deviation to 1.\n",
    "standardScaler = StandardScaler()\n",
    "train_features = standardScaler.fit_transform(train_features)\n",
    "val_features = standardScaler.transform(val_features)\n",
    "test_features = standardScaler.transform(test_features)\n",
    "\n",
    "\n",
    "# save standardScaler for TRSS use\n",
    "try: \n",
    "    standardScaler_file = open('data/TempData/standardScaler_file.pk', 'wb')\n",
    "    pickle.dump(standardScaler, standardScaler_file)\n",
    "    standardScaler_file.close()\n",
    "except: \n",
    "    print(\"Failed to save standardScaler_file\")\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Preliminary models evaluation with default parameters\n",
    "\n",
    "# Creating a dict of the several models\n",
    "# Temporarily use only two models to reduce training time\n",
    "model_dict = {'Decsision Tree Model': DecisionTreeClassifier(random_state=3),\n",
    "              # 'Dummy Model' : DummyClassifier(random_state=3),\n",
    "              # 'Stochastic Gradient Descent Model' : SGDClassifier(random_state=3, loss='log'),\n",
    "              # 'AdaBoost Model': AdaBoostClassifier(random_state=3),\n",
    "              # 'Gaussian Naive Bayes Model': GaussianNB(),\n",
    "              # 'K Nearest Neighbor Model': KNeighborsClassifier(),\n",
    "              'Random Forest Model': RandomForestClassifier(random_state=3)}\n",
    "\n",
    "# Train test split with stratified sampling for evaluation\n",
    "# X_train, X_test, y_train, y_test = train_features, val_features, train_labels, val_labels\n",
    "X_train, X_test, y_train, y_test = train_features, test_features, train_labels, test_labels\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "#                                                     y, \n",
    "#                                                     test_size = .3, \n",
    "#                                                     shuffle = True, \n",
    "#                                                     stratify = y, \n",
    "#                                                     random_state = 3)\n",
    "\n",
    "#Function to get the scores for each model in a df\n",
    "def model_scores_df(model_dict):   \n",
    "    model_names, ac_scores_list, p_scores_list, r_scores_list, f1_scores_list = [], [], [], [], []\n",
    "    for cur_model_name,cur_model in model_dict.items():   \n",
    "        model_names.append(cur_model_name)\n",
    "        cur_model.fit(X_train, y_train)\n",
    "        label_pred = cur_model.predict(X_test)\n",
    "        ac_scores_list.append(accuracy_score(y_test, label_pred))\n",
    "        p_scores_list.append(precision_score(y_test, label_pred, average='macro'))\n",
    "        r_scores_list.append(recall_score(y_test, label_pred, average='macro'))\n",
    "        f1_scores_list.append(f1_score(y_test, label_pred, average='macro'))\n",
    "    \n",
    "    model_comparison_df = pd.DataFrame([model_names, ac_scores_list, p_scores_list, r_scores_list, f1_scores_list]).T\n",
    "    model_comparison_df.columns = ['model_names', 'accuracy_scores', 'precision_scores', 'recall_scores', 'f1_scores']\n",
    "        \n",
    "    model_comparison_df = model_comparison_df.sort_values(by='f1_scores', ascending=False).reset_index(drop=True)\n",
    "    return model_comparison_df\n",
    "\n",
    "scores_df = model_scores_df(model_dict)\n",
    "scores_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Saving and loading the best model\n",
    "\n",
    "best_model_name = scores_df[\"model_names\"][0]\n",
    "print(\"Best model found:\", best_model_name)\n",
    "best_model = model_dict[best_model_name]\n",
    "\n",
    "#Save the best model\n",
    "dump(best_model, 'MLModel.joblib')\n",
    "\n",
    "#Load the best model\n",
    "saved_best_model = load('MLModel.joblib')\n",
    "\n",
    "#Predict with the best model\n",
    "saved_best_model_predictions = saved_best_model.predict(test_features)\n",
    "saved_best_model_predictions_proba = saved_best_model.predict_proba(test_features)\n",
    "\n",
    "print(\"Saved_Best_Model Sample 0 predicted label:\", saved_best_model_predictions[0])\n",
    "print(\"Saved_Best_Model Sample 0 prediction probability:\", saved_best_model_predictions_proba[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "interpreter": {
   "hash": "1d7df3b423b2d484b1f899ddd32916b28c4dd363bf4b96c943ce9c38221f460d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}